{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAS05052022.ipynb",
      "provenance": [],
      "mount_file_id": "1fhoFcGi-qEQEnvPQDeeQQv8z_q0laPa1",
      "authorship_tag": "ABX9TyOx27FMS1ozXou5JpBKetfN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NAS with auto-pytorch\n",
        "Modelle des Ensembles anzeigen"
      ],
      "metadata": {
        "id": "7jRONP6-0kIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGMPHDLPvTEN",
        "outputId": "14bd42b8-5035-4d22-c29d-6c61dcc88bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: autoPyTorch in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (2022.2.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (1.0.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.8.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (1.3.5)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (3.7.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (1.7.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (2.2.3)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.7 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.8.2)\n",
            "Requirement already satisfied: smac==0.14.0 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.14.0)\n",
            "Requirement already satisfied: pynisher>=0.6.3 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.6.4)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.24.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (2.8.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.12.0+cu113)\n",
            "Requirement already satisfied: distributed>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (2022.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (1.21.6)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.4.21)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.7/dist-packages (from autoPyTorch) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from smac==0.14.0->autoPyTorch) (5.4.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from smac==0.14.0->autoPyTorch) (1.1.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->autoPyTorch) (0.29.28)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->autoPyTorch) (3.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (2.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (21.3)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (7.1.2)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (1.0.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (5.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (0.11.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (2.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (2.11.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (1.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (57.4.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->autoPyTorch) (2.4.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask->autoPyTorch) (2022.3.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask->autoPyTorch) (1.2.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (1.8.1.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->autoPyTorch) (1.15.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask->autoPyTorch) (1.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->autoPyTorch) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->autoPyTorch) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->autoPyTorch) (1.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->autoPyTorch) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->autoPyTorch) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->autoPyTorch) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->autoPyTorch) (4.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.24.0->autoPyTorch) (3.1.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.2.0->autoPyTorch) (1.0.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost->autoPyTorch) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost->autoPyTorch) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autoPyTorch) (2022.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.2.0->autoPyTorch) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost->autoPyTorch) (8.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (1.44.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->autoPyTorch) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autoPyTorch) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autoPyTorch) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autoPyTorch) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->autoPyTorch) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->autoPyTorch) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->autoPyTorch) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autoPyTorch) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->autoPyTorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->autoPyTorch) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->autoPyTorch) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->autoPyTorch) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->autoPyTorch) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xlrd # important to upgrade to open xls file\n",
        "!pip install autoPyTorch \n",
        "\n",
        "# import needed packages\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.ensemble\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Train and Test Data\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/AutoML/Concrete_Data.xls', engine='xlrd')\n",
        "X = data.iloc[:, 0:8].to_numpy()\n",
        "y = data.iloc[:, 8].to_numpy()\n",
        "\n",
        "print('Size of X: ', X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    sklearn.model_selection.train_test_split(X, y,random_state=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8MNEgovczi",
        "outputId": "b9d4a487-29a1-4345-80cf-6d7cc3cce9fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X:  (1030, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TabularRegressionTask from autoPyTorch\n",
        "from autoPyTorch.api.tabular_regression import TabularRegressionTask\n",
        "\n",
        "api = TabularRegressionTask()\n",
        "\n",
        "# .search() takes train and test data, asks for optimization metric and how long the algorithm should run.\n",
        "# set memory_limit=None to use complete memory instead of default 4096 MB, so that used algorithms dont crash.\n",
        "api.search(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test.copy(),\n",
        "    y_test=y_test.copy(),\n",
        "    optimize_metric='r2',\n",
        "    total_walltime_limit=1000,\n",
        "    func_eval_time_limit_secs=50,\n",
        "    memory_limit=None,\n",
        "    enable_traditional_pipeline=False # just NNs and not kNN and traditional stuff...\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNsMhS3hvhEV",
        "outputId": "772d4aaf-e081-4a3e-fdbf-f906dd14407f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] [2022-05-05 12:14:56,231:Client-Validation] AutoPyTorch previously received features of type <class 'numpy.ndarray'> yet the current features have type <class 'pandas.core.frame.DataFrame'>. Changing the dtype of inputs to an estimator might cause problems\n",
            "[WARNING] [2022-05-05 12:14:56,258:Client-Validation] AutoPyTorch previously received features of type <class 'numpy.ndarray'> yet the current features have type <class 'pandas.core.frame.DataFrame'>. Changing the dtype of inputs to an estimator might cause problems\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n",
            "/usr/local/lib/python3.7/dist-packages/smac/intensification/parallel_scheduling.py:152: UserWarning: Hyperband is intended to be used with more than 1 worker but num_workers=1\n",
            "  num_workers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autoPyTorch.api.tabular_regression.TabularRegressionTask at 0x7f1be4513610>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = api.predict(X_test)\n",
        "\n",
        "# Rescale the Neural Network predictions into the original target range\n",
        "score = api.score(y_pred, y_test)\n",
        "\n",
        "print(score)\n",
        "\n",
        "# Print the final ensemble built by AutoPyTorch\n",
        "print(api.show_models())\n",
        "\n",
        "# Print statistics from search\n",
        "print(api.sprint_statistics())\n",
        "\n",
        "# wie wird der validation score gemessen?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uj8VhgFvjks",
        "outputId": "baaeee15-852e-4e92-e56f-25c5e109f3d0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'r2': 0.8819549312612294}\n",
            "|    | Preprocessing                                                 | Estimator                                                       |   Weight |\n",
            "|---:|:--------------------------------------------------------------|:----------------------------------------------------------------|---------:|\n",
            "|  0 | SimpleImputer,NoEncoder,StandardScaler,NoFeaturePreprocessing | no embedding,ShapedMLPBackbone,FullyConnectedHead,nn.Sequential |     0.92 |\n",
            "|  1 | SimpleImputer,NoEncoder,Normalizer,PolynomialFeatures         | no embedding,MLPBackbone,FullyConnectedHead,nn.Sequential       |     0.06 |\n",
            "|  2 | SimpleImputer,NoEncoder,StandardScaler,NoFeaturePreprocessing | no embedding,ShapedMLPBackbone,FullyConnectedHead,nn.Sequential |     0.02 |\n",
            "autoPyTorch results:\n",
            "\tDataset name: f9234d5e-cc6c-11ec-81bd-0242ac1c0002\n",
            "\tOptimisation Metric: r2\n",
            "\tBest validation score: 0.9090103249648109\n",
            "\tNumber of target algorithm runs: 53\n",
            "\tNumber of successful target algorithm runs: 48\n",
            "\tNumber of crashed target algorithm runs: 1\n",
            "\tNumber of target algorithms that exceeded the time limit: 4\n",
            "\tNumber of target algorithms that exceeded the memory limit: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(api.models_)"
      ],
      "metadata": {
        "id": "yyd_2Lojw8Ax",
        "outputId": "579740c8-6c39-4f5d-997b-d61185771d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(1, 12, 50.0): ________________________________________\n",
            "\tTabularRegressionPipeline\n",
            "________________________________________\n",
            "0-) imputer: \n",
            "\tSimpleImputer\n",
            "\n",
            "1-) encoder: \n",
            "\tNoEncoder\n",
            "\n",
            "2-) scaler: \n",
            "\tNormalizer\n",
            "\n",
            "3-) feature_preprocessor: \n",
            "\tPolynomialFeatures\n",
            "\n",
            "4-) tabular_transformer: \n",
            "\tTabularColumnTransformer\n",
            "\n",
            "5-) preprocessing: \n",
            "\tEarlyPreprocessing\n",
            "\n",
            "6-) network_embedding: \n",
            "\tautoPyTorch.pipeline NoEmbedding\n",
            "\n",
            "7-) network_backbone: \n",
            "\tautoPyTorch.pipeline MLPBackbone\n",
            "\n",
            "8-) network_head: \n",
            "\tautoPyTorch.pipeline FullyConnectedHead\n",
            "\n",
            "9-) network: \n",
            "\tSequential ({'random_state': RandomState(MT19937) at 0x7F1BE486DAF0, '_fit_requirements': [FitRequirement(name='network_head', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_backbone', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_embedding', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'device': device(type='cpu'), 'network': Sequential(\n",
            "  (0): _NoEmbedding()\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=45, out_features=651, bias=True)\n",
            "    (1): BatchNorm1d(651, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3040903538310315, inplace=False)\n",
            "    (4): Linear(in_features=651, out_features=848, bias=True)\n",
            "    (5): BatchNorm1d(848, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0.760263256515859, inplace=False)\n",
            "    (8): Linear(in_features=848, out_features=39, bias=True)\n",
            "    (9): BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): Dropout(p=0.05648995653345228, inplace=False)\n",
            "    (12): Linear(in_features=39, out_features=62, bias=True)\n",
            "    (13): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): Dropout(p=0.19376256488855248, inplace=False)\n",
            "    (16): Linear(in_features=62, out_features=195, bias=True)\n",
            "    (17): BatchNorm1d(195, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU()\n",
            "    (19): Dropout(p=0.19619760139722608, inplace=False)\n",
            "    (20): Linear(in_features=195, out_features=599, bias=True)\n",
            "    (21): BatchNorm1d(599, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): Dropout(p=0.6423500017493856, inplace=False)\n",
            "    (24): Linear(in_features=599, out_features=701, bias=True)\n",
            "    (25): BatchNorm1d(701, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU()\n",
            "    (27): Dropout(p=0.7061880110190955, inplace=False)\n",
            "    (28): Linear(in_features=701, out_features=389, bias=True)\n",
            "    (29): BatchNorm1d(389, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (30): ReLU()\n",
            "    (31): Dropout(p=0.16632649863136414, inplace=False)\n",
            "    (32): Linear(in_features=389, out_features=320, bias=True)\n",
            "    (33): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (34): ReLU()\n",
            "    (35): Dropout(p=0.2952197309508763, inplace=False)\n",
            "    (36): Linear(in_features=320, out_features=689, bias=True)\n",
            "    (37): BatchNorm1d(689, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU()\n",
            "    (39): Dropout(p=0.5890923434877329, inplace=False)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=689, out_features=271, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): Linear(in_features=271, out_features=276, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=276, out_features=1, bias=True)\n",
            "  )\n",
            "), 'final_activation': None, 'is_fitted_': True})\n",
            "\n",
            "10-) network_init: \n",
            "\tNoInit\n",
            "\n",
            "11-) optimizer: \n",
            "\tRMSprop ({'random_state': RandomState(MT19937) at 0x7F1BE486DAF0, '_fit_requirements': [FitRequirement(name='network', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'optimizer': RMSprop (\n",
            "Parameter Group 0\n",
            "    alpha: 0.9887300619574456\n",
            "    centered: False\n",
            "    eps: 1e-08\n",
            "    lr: 5.186867512910672e-05\n",
            "    momentum: 0.5710753844311705\n",
            "    weight_decay: 0.09205922546817208\n",
            "), 'lr': 0.0009095986653087319, 'momentum': 0.5710753844311705, 'alpha': 0.9887300619574456, 'weight_decay': 0.09205922546817208})\n",
            "\n",
            "12-) lr_scheduler: \n",
            "\tReduceLROnPlateau\n",
            "\n",
            "13-) data_loader: \n",
            "\tDataLoader\n",
            "\n",
            "14-) trainer: \n",
            "\tautoPyTorch.pipeline MixUp Regularized Trainer\n",
            "\n",
            "________________________________________, (1, 2, 5.555555555555555): ________________________________________\n",
            "\tTabularRegressionPipeline\n",
            "________________________________________\n",
            "0-) imputer: \n",
            "\tSimpleImputer\n",
            "\n",
            "1-) encoder: \n",
            "\tNoEncoder\n",
            "\n",
            "2-) scaler: \n",
            "\tStandardScaler\n",
            "\n",
            "3-) feature_preprocessor: \n",
            "\tNoFeaturePreprocessor\n",
            "\n",
            "4-) tabular_transformer: \n",
            "\tTabularColumnTransformer\n",
            "\n",
            "5-) preprocessing: \n",
            "\tEarlyPreprocessing\n",
            "\n",
            "6-) network_embedding: \n",
            "\tautoPyTorch.pipeline NoEmbedding\n",
            "\n",
            "7-) network_backbone: \n",
            "\tautoPyTorch.pipeline ShapedMLPBackbone\n",
            "\n",
            "8-) network_head: \n",
            "\tautoPyTorch.pipeline FullyConnectedHead\n",
            "\n",
            "9-) network: \n",
            "\tSequential ({'random_state': RandomState(MT19937) at 0x7F1BE44E47C0, '_fit_requirements': [FitRequirement(name='network_head', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_backbone', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_embedding', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'device': device(type='cpu'), 'network': Sequential(\n",
            "  (0): _NoEmbedding()\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=8, out_features=200, bias=True)\n",
            "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (10): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=200, out_features=200, bias=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=200, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            "), 'final_activation': None, 'is_fitted_': True})\n",
            "\n",
            "10-) network_init: \n",
            "\tXavierInit\n",
            "\n",
            "11-) optimizer: \n",
            "\tAdam ({'random_state': RandomState(MT19937) at 0x7F1BE44E47C0, '_fit_requirements': [FitRequirement(name='network', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'optimizer': Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.9)\n",
            "    eps: 1e-08\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "), 'lr': 0.01, 'beta1': 0.9, 'beta2': 0.9, 'weight_decay': 0.0})\n",
            "\n",
            "12-) lr_scheduler: \n",
            "\tReduceLROnPlateau\n",
            "\n",
            "13-) data_loader: \n",
            "\tDataLoader\n",
            "\n",
            "14-) trainer: \n",
            "\tautoPyTorch.pipeline Standard Trainer\n",
            "\n",
            "________________________________________, (1, 2, 50.0): ________________________________________\n",
            "\tTabularRegressionPipeline\n",
            "________________________________________\n",
            "0-) imputer: \n",
            "\tSimpleImputer\n",
            "\n",
            "1-) encoder: \n",
            "\tNoEncoder\n",
            "\n",
            "2-) scaler: \n",
            "\tStandardScaler\n",
            "\n",
            "3-) feature_preprocessor: \n",
            "\tNoFeaturePreprocessor\n",
            "\n",
            "4-) tabular_transformer: \n",
            "\tTabularColumnTransformer\n",
            "\n",
            "5-) preprocessing: \n",
            "\tEarlyPreprocessing\n",
            "\n",
            "6-) network_embedding: \n",
            "\tautoPyTorch.pipeline NoEmbedding\n",
            "\n",
            "7-) network_backbone: \n",
            "\tautoPyTorch.pipeline ShapedMLPBackbone\n",
            "\n",
            "8-) network_head: \n",
            "\tautoPyTorch.pipeline FullyConnectedHead\n",
            "\n",
            "9-) network: \n",
            "\tSequential ({'random_state': RandomState(MT19937) at 0x7F1BE42A6E20, '_fit_requirements': [FitRequirement(name='network_head', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_backbone', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False), FitRequirement(name='network_embedding', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'device': device(type='cpu'), 'network': Sequential(\n",
            "  (0): _NoEmbedding()\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=8, out_features=200, bias=True)\n",
            "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (10): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=200, out_features=200, bias=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=200, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            "), 'final_activation': None, 'is_fitted_': True})\n",
            "\n",
            "10-) network_init: \n",
            "\tXavierInit\n",
            "\n",
            "11-) optimizer: \n",
            "\tAdam ({'random_state': RandomState(MT19937) at 0x7F1BE42A6E20, '_fit_requirements': [FitRequirement(name='network', supported_types=(<class 'torch.nn.modules.module.Module'>,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'optimizer': Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.9)\n",
            "    eps: 1e-08\n",
            "    lr: 1.0000000000000002e-06\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "), 'lr': 0.01, 'beta1': 0.9, 'beta2': 0.9, 'weight_decay': 0.0})\n",
            "\n",
            "12-) lr_scheduler: \n",
            "\tReduceLROnPlateau\n",
            "\n",
            "13-) data_loader: \n",
            "\tDataLoader\n",
            "\n",
            "14-) trainer: \n",
            "\tautoPyTorch.pipeline Standard Trainer\n",
            "\n",
            "________________________________________}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto-sklearn\n",
        "Switching to auto-sklearn. AutoPyTorch is based on auto-sklearn so using auto-sklearn might reveal more about AutoPyTorch Functionalities since the Documentation is poor."
      ],
      "metadata": {
        "id": "-wkZG49Dw72e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Train and Test Data\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/AutoML/Concrete_Data.xls', engine='xlrd')\n",
        "X = data.iloc[:, 0:8].to_numpy()\n",
        "y = data.iloc[:, 8].to_numpy()\n",
        "\n",
        "print('Size of X: ', X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    sklearn.model_selection.train_test_split(X, y,random_state=1)"
      ],
      "metadata": {
        "id": "e88H-Lak0qVc",
        "outputId": "8d4db52b-cb38-4f31-ba1b-210a99633bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X:  (1030, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8l-0SRXV0xSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
