{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of https://iopscience.iop.org/article/10.1088/1742-6596/1325/1/012079/pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirtualSampleGeneration():\n",
    "    def __init__(self, train_input, train_output):\n",
    "        self.train_input = train_input\n",
    "        self.train_output = train_output\n",
    "        self.x_min = train_input.min(axis=0)\n",
    "        self.x_max = train_input.max(axis=0)\n",
    "        self.cl = (self.x_min + self.x_max)*0.5\n",
    "        self.attributes = train_input.shape[1]\n",
    "        self.n = train_input.shape[0]\n",
    "        self.x_var = train_input.var(axis=0)/(self.n-1)\n",
    "        self.eta = np.log(10**(-20)) # parameter for numeric stability\n",
    "        self.lb, self.ub = self.get_ub_lb()\n",
    "\n",
    "        \n",
    "\n",
    "    def get_ub_lb(self):\n",
    "        x_min = self.x_min\n",
    "        x_max = self.x_max\n",
    "        attributes = self.attributes\n",
    "        x_var = self.x_var\n",
    "\n",
    "        # Berechne Center of Attributes CL\n",
    "        cl = self.cl\n",
    "\n",
    "        # Berechnung NL, NU f√ºr Xi (amount of samples smaller than CL)\n",
    "        nu = []\n",
    "        nl = []\n",
    "        for i in range(attributes):\n",
    "            nl_i = (X[:, i] <= cl[i]).nonzero()[0].shape[0]\n",
    "            nu_i = (X[:, i] > cl[i]).nonzero()[0].shape[0]\n",
    "\n",
    "            nl.append(nl_i)\n",
    "            nu.append(nu_i)\n",
    "\n",
    "        nl = np.array(nl)\n",
    "        nu = np.array(nu)\n",
    "\n",
    "        # Berechnung SkewL, SKewU\n",
    "        skew_l = nl/(nl + nu)\n",
    "        skew_u = nu/(nl + nu)\n",
    "\n",
    "        lb = cl - skew_l*np.sqrt(-2*x_var/nl*eta)\n",
    "        ub = cl + skew_l*np.sqrt(-2*x_var/nu*eta)\n",
    "        return lb, ub\n",
    "    \n",
    "    def _mf_for_attribute(self, i):\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "        cl = self.cl\n",
    "\n",
    "        MF = []\n",
    "        x_range = np.linspace(lb[i], ub[i], 100)\n",
    "        for x in x_range:\n",
    "            lb_to_cl = (x - lb[i]) / (cl[i] - lb[i])\n",
    "            ub_from_cl = (ub[i] - x) / (ub[i] - cl[i])\n",
    "\n",
    "            if (lb[i] <= x and x < cl[i]):\n",
    "                MF.append(lb_to_cl)\n",
    "            elif (cl[i] <= x and x <=ub[i]):\n",
    "                MF.append(ub_from_cl)\n",
    "            else:\n",
    "                MF.append(0)\n",
    "        return np.array(MF), x_range\n",
    "\n",
    "    def mf_all(self):\n",
    "        attributes = self.attributes\n",
    "        MF = []\n",
    "        ranges = []\n",
    "        for i in range(attributes):\n",
    "            mfi, x_range = self._mf_for_attribute(i)\n",
    "            MF.append(mfi)\n",
    "            ranges.append(x_range)\n",
    "        return MF, ranges\n",
    "    \n",
    "    # Latin Hypercube Sampling\n",
    "    def get_samples(self, n):\n",
    "        # generate n samples\n",
    "        from scipy.stats.qmc import LatinHypercube\n",
    "        import scipy.stats.qmc as qmc\n",
    "        attributes = self.attributes\n",
    "        lb = self.lb\n",
    "        ub = self.ub\n",
    "\n",
    "        sampler = LatinHypercube(attributes)\n",
    "        sample = sampler.random(n)\n",
    "        return qmc.scale(sample, lb, ub)\n",
    "    \n",
    "    # Generate Labels with Model\n",
    "    def get_labels(self, model, samples):\n",
    "        train_input = self.train_input\n",
    "        train_output = self.train_output\n",
    "        model.fit(train_input, train_output)\n",
    "        y_samples = model.predict(samples)\n",
    "        return y_samples\n",
    "\n",
    "    # Add the data to train data set\n",
    "    def add_virtual_data(self, model, n):\n",
    "        additional_train_input = self.get_samples(n)\n",
    "        additional_train_output = self.get_labels(model, additional_train_input)\n",
    "\n",
    "        self.train_input = np.vstack((self.train_input, additional_train_input))\n",
    "        self.train_output = np.hstack((self.train_output, additional_train_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohne VSG\n",
      "Train RMSE:  1.3768546647061861\n",
      "Train R2:  0.9674328616276255\n",
      "Test RMSE:  3.3502304047220997\n",
      "Test R2:  0.8251633242631613\n",
      "Mit VSG\n",
      "Train RMSE:  0.8814801103286092\n",
      "Train R2:  0.9723395274886042\n",
      "Test RMSE:  3.2513032473501537\n",
      "Test R2:  0.8353361958054434\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"slump_test.csv\")\n",
    "\n",
    "X = data.iloc[:, 1:10].values\n",
    "y = data.iloc[:, 10].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ohne VSG\n",
    "print('ohne VSG')\n",
    "model = RandomForestRegressor(n_estimators=400, max_depth=9)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('Train RMSE: ',np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('Train R2: ', model.score(X_train, y_train))\n",
    "print('Test RMSE: ',np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('Test R2: ', model.score(X_test, y_test))\n",
    "\n",
    "# Mit VSG\n",
    "print('Mit VSG')\n",
    "vsg = VirtualSampleGeneration(X_train, y_train)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=400, max_depth=9)\n",
    "vsg.add_virtual_data(model, 100)\n",
    "\n",
    "snew_X_train = vsg.train_input\n",
    "snew_y_train = vsg.train_output\n",
    "\n",
    "model.fit(snew_X_train, snew_y_train)\n",
    "y_pred = model.predict(snew_X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('Train RMSE: ',np.sqrt(mean_squared_error(snew_y_train, y_pred)))\n",
    "print('Train R2: ', model.score(snew_X_train, snew_y_train))\n",
    "print('Test RMSE: ',np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('Test R2: ', model.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Coding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd654090bd74163e3c21ddf3a28fdcb0b550d3554b0ed7c75a13fe37954fb75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
